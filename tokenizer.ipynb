{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca1ca345-7dbe-4e4f-90c0-752374785651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Tuple\n",
    "import regex\n",
    "import tiktoken\n",
    "import sentencepiece as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "70d99252-4e2c-4ce4-8b03-292759393982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x00'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3bb489b-57a0-450d-8181-af70ecb5ee6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_without_merging(string_input: str):\n",
    "    return list(string_input.encode(\"utf-8\"))\n",
    "\n",
    "\n",
    "def encode(string_input: str, merges: Dict[Tuple, int]):\n",
    "    tokens = list(string_input.encode(\"utf-8\"))\n",
    "    while len(tokens) >= 2:\n",
    "        pair_cnts = get_pair_cnt(tokens)\n",
    "        pair = min(pair_cnts, key=lambda p: merges.get(p, float(\"inf\")))\n",
    "        if pair not in merges:\n",
    "            break\n",
    "        idx = merges[pair]\n",
    "        print(\"pair\", pair)\n",
    "        print(\"index\", idx)\n",
    "        tokens = mint_new_token(tokens, pair, idx)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def build_vocab(merge_dict: Dict) -> Dict[int, str]:\n",
    "    vocab = {idx: bytes([idx]) for idx in range(256)}\n",
    "    for (p0, p1), idx in merge_dict.items():\n",
    "        print(vocab[p0] + vocab[p1])\n",
    "        vocab[idx] = vocab[p0] + vocab[p1]\n",
    "    return vocab\n",
    "\n",
    "\n",
    "def decode(ids: int, vocab: Dict[int, str]):\n",
    "    tokens = b\"\".join(vocab[idx] for idx in ids)\n",
    "    print(tokens)\n",
    "    text = tokens.decode(\"utf-8\", errors=\"replace\")\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_pair_cnt(ids: List[int]):\n",
    "    counts = {}\n",
    "    for pair in zip(ids, ids[1:]):\n",
    "        counts[pair] = counts.get(pair, 0) + 1\n",
    "    return counts\n",
    "\n",
    "\n",
    "def get_top_pair(ids: List[int]) -> Tuple[int, ...]:\n",
    "    pair_cnts = get_pair_cnt(ids)\n",
    "    top_pair = max(pair_cnts, key=pair_cnts.get)\n",
    "    return top_pair\n",
    "\n",
    "\n",
    "def mint_new_token(ids: List[int], pair: Tuple[int, ...], idx: int):\n",
    "    newIds = []\n",
    "    i = 0\n",
    "    while i < len(ids):\n",
    "        if i < len(ids) - 1 and ids[i] == pair[0] and ids[i + 1] == pair[1]:\n",
    "            newIds.append(idx)\n",
    "            i += 2\n",
    "        else:\n",
    "            newIds.append(ids[i])\n",
    "            i += 1\n",
    "    return newIds\n",
    "\n",
    "\n",
    "def get_compression_ratio(tokens: List[int], ids: List[int]):\n",
    "    print(\"length of the tokens:\", len(tokens))\n",
    "    print(\"length of the ids:\", len(ids))\n",
    "    print(\"compression ratio:\", round(len(tokens) / len(ids), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11905a52-15cc-4bce-8b0b-9fa15154dbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x00'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8ecd5793-0f14-4901-b851-f0e5c30e1bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_str: str = \"hi hello 😆, how are you doing ? お元気ですか \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "900a1a7b-9ceb-4995-8dc9-8e94ea5e1630",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_string = \"Ｕｎｉｃｏｄｅ! 🅤🅝🅘🅒🅞🅓🅔‽ 🇺‌🇳‌🇮‌🇨‌🇴‌🇩‌🇪! 😄 The very name strikes fear and awe into the hearts of programmers worldwide. We all know we ought to “support Unicode” in our software (whatever that means—like using wchar_t for all the strings, right?). But Unicode can be abstruse, and diving into the thousand-page Unicode Standard plus its dozens of supplementary annexes, reports, and notes can be more than a little intimidating. I don’t blame programmers for still finding the whole thing mysterious, even 30 years after Unicode’s inception.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f9552eb3-a583-47ad-a272-2ab18288728b",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_tokens = encode_without_merging(paragraph_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "080f7300-e6d1-4875-9dbb-7f4737945fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_string_tokens = encode_without_merging(random_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f237566-ca5a-49ff-b127-28b6631380d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[104,\n",
       " 105,\n",
       " 32,\n",
       " 104,\n",
       " 101,\n",
       " 108,\n",
       " 108,\n",
       " 111,\n",
       " 32,\n",
       " 240,\n",
       " 159,\n",
       " 152,\n",
       " 134,\n",
       " 44,\n",
       " 32,\n",
       " 104,\n",
       " 111,\n",
       " 119,\n",
       " 32,\n",
       " 97,\n",
       " 114,\n",
       " 101,\n",
       " 32,\n",
       " 121,\n",
       " 111,\n",
       " 117,\n",
       " 32,\n",
       " 100,\n",
       " 111,\n",
       " 105,\n",
       " 110,\n",
       " 103,\n",
       " 32,\n",
       " 63,\n",
       " 32,\n",
       " 227,\n",
       " 129,\n",
       " 138,\n",
       " 229,\n",
       " 133,\n",
       " 131,\n",
       " 230,\n",
       " 176,\n",
       " 151,\n",
       " 227,\n",
       " 129,\n",
       " 167,\n",
       " 227,\n",
       " 129,\n",
       " 153,\n",
       " 227,\n",
       " 129,\n",
       " 139,\n",
       " 32]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_string_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d08cd61d-9272-42e5-94cf-b622f8e88f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the vocab size\n",
    "vocab_size = 300\n",
    "n_merges = vocab_size - 256\n",
    "# copy the tokens list\n",
    "ids = list(paragraph_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c606d67a-88af-424e-b8a9-ef84d6af5de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merging (101, 32) into a new token 256\n",
      "merging (240, 159) into a new token 257\n",
      "merging (226, 128) into a new token 258\n",
      "merging (105, 110) into a new token 259\n",
      "merging (115, 32) into a new token 260\n",
      "merging (97, 110) into a new token 261\n",
      "merging (116, 104) into a new token 262\n",
      "merging (257, 133) into a new token 263\n",
      "merging (257, 135) into a new token 264\n",
      "merging (97, 114) into a new token 265\n",
      "merging (239, 189) into a new token 266\n",
      "merging (258, 140) into a new token 267\n",
      "merging (267, 264) into a new token 268\n",
      "merging (101, 114) into a new token 269\n",
      "merging (111, 114) into a new token 270\n",
      "merging (116, 32) into a new token 271\n",
      "merging (259, 103) into a new token 272\n",
      "merging (115, 116) into a new token 273\n",
      "merging (261, 100) into a new token 274\n",
      "merging (32, 262) into a new token 275\n",
      "merging (44, 32) into a new token 276\n",
      "merging (97, 109) into a new token 277\n",
      "merging (275, 256) into a new token 278\n",
      "merging (111, 117) into a new token 279\n",
      "merging (85, 110) into a new token 280\n",
      "merging (280, 105) into a new token 281\n",
      "merging (281, 99) into a new token 282\n",
      "merging (282, 111) into a new token 283\n",
      "merging (283, 100) into a new token 284\n",
      "merging (115, 276) into a new token 285\n",
      "merging (273, 114) into a new token 286\n",
      "merging (101, 265) into a new token 287\n",
      "merging (274, 32) into a new token 288\n",
      "merging (259, 116) into a new token 289\n",
      "merging (111, 102) into a new token 290\n",
      "merging (46, 32) into a new token 291\n",
      "merging (108, 108) into a new token 292\n",
      "merging (272, 32) into a new token 293\n",
      "merging (261, 32) into a new token 294\n",
      "merging (101, 110) into a new token 295\n",
      "merging (33, 32) into a new token 296\n",
      "merging (118, 269) into a new token 297\n",
      "merging (121, 32) into a new token 298\n",
      "merging (277, 256) into a new token 299\n"
     ]
    }
   ],
   "source": [
    "merges = {}\n",
    "for i in range(n_merges):\n",
    "    top_pair = get_top_pair(ids)\n",
    "    idx = 256 + i\n",
    "    print(f\"merging {top_pair} into a new token {idx}\")\n",
    "    ids = mint_new_token(ids, top_pair, idx)\n",
    "    merges[top_pair] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3229d9c-e458-433e-969c-7a8c508cb74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(101, 32): 256,\n",
       " (240, 159): 257,\n",
       " (226, 128): 258,\n",
       " (105, 110): 259,\n",
       " (115, 32): 260,\n",
       " (97, 110): 261,\n",
       " (116, 104): 262,\n",
       " (257, 133): 263,\n",
       " (257, 135): 264,\n",
       " (97, 114): 265,\n",
       " (239, 189): 266,\n",
       " (258, 140): 267,\n",
       " (267, 264): 268,\n",
       " (101, 114): 269,\n",
       " (111, 114): 270,\n",
       " (116, 32): 271,\n",
       " (259, 103): 272,\n",
       " (115, 116): 273,\n",
       " (261, 100): 274,\n",
       " (32, 262): 275,\n",
       " (44, 32): 276,\n",
       " (97, 109): 277,\n",
       " (275, 256): 278,\n",
       " (111, 117): 279,\n",
       " (85, 110): 280,\n",
       " (280, 105): 281,\n",
       " (281, 99): 282,\n",
       " (282, 111): 283,\n",
       " (283, 100): 284,\n",
       " (115, 276): 285,\n",
       " (273, 114): 286,\n",
       " (101, 265): 287,\n",
       " (274, 32): 288,\n",
       " (259, 116): 289,\n",
       " (111, 102): 290,\n",
       " (46, 32): 291,\n",
       " (108, 108): 292,\n",
       " (272, 32): 293,\n",
       " (261, 32): 294,\n",
       " (101, 110): 295,\n",
       " (33, 32): 296,\n",
       " (118, 269): 297,\n",
       " (121, 32): 298,\n",
       " (277, 256): 299}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ca54e51-80bc-4726-8e85-aedae49b854f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of the tokens: 616\n",
      "length of the ids: 372\n",
      "compression ratio: 1.66\n"
     ]
    }
   ],
   "source": [
    "get_compression_ratio(paragraph_tokens, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc31707f-2df3-4166-b25e-b2995b45b5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair (101, 32)\n",
      "index 256\n",
      "pair (240, 159)\n",
      "index 257\n",
      "pair (105, 110)\n",
      "index 259\n",
      "pair (97, 114)\n",
      "index 265\n",
      "pair (259, 103)\n",
      "index 272\n",
      "pair (44, 32)\n",
      "index 276\n",
      "pair (111, 117)\n",
      "index 279\n",
      "pair (108, 108)\n",
      "index 292\n",
      "pair (272, 32)\n",
      "index 293\n"
     ]
    }
   ],
   "source": [
    "encoded_random_str = encode(random_str, merges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6ae1989-37df-4a53-89d3-97b7b816dfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'e '\n",
      "b'\\xf0\\x9f'\n",
      "b'\\xe2\\x80'\n",
      "b'in'\n",
      "b's '\n",
      "b'an'\n",
      "b'th'\n",
      "b'\\xf0\\x9f\\x85'\n",
      "b'\\xf0\\x9f\\x87'\n",
      "b'ar'\n",
      "b'\\xef\\xbd'\n",
      "b'\\xe2\\x80\\x8c'\n",
      "b'\\xe2\\x80\\x8c\\xf0\\x9f\\x87'\n",
      "b'er'\n",
      "b'or'\n",
      "b't '\n",
      "b'ing'\n",
      "b'st'\n",
      "b'and'\n",
      "b' th'\n",
      "b', '\n",
      "b'am'\n",
      "b' the '\n",
      "b'ou'\n",
      "b'Un'\n",
      "b'Uni'\n",
      "b'Unic'\n",
      "b'Unico'\n",
      "b'Unicod'\n",
      "b's, '\n",
      "b'str'\n",
      "b'ear'\n",
      "b'and '\n",
      "b'int'\n",
      "b'of'\n",
      "b'. '\n",
      "b'll'\n",
      "b'ing '\n",
      "b'an '\n",
      "b'en'\n",
      "b'! '\n",
      "b'ver'\n",
      "b'y '\n",
      "b'ame '\n"
     ]
    }
   ],
   "source": [
    "vocab = build_vocab(merges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ae3f2d6-0e7c-4207-8a66-6afbc3e220ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: b'\\x00',\n",
       " 1: b'\\x01',\n",
       " 2: b'\\x02',\n",
       " 3: b'\\x03',\n",
       " 4: b'\\x04',\n",
       " 5: b'\\x05',\n",
       " 6: b'\\x06',\n",
       " 7: b'\\x07',\n",
       " 8: b'\\x08',\n",
       " 9: b'\\t',\n",
       " 10: b'\\n',\n",
       " 11: b'\\x0b',\n",
       " 12: b'\\x0c',\n",
       " 13: b'\\r',\n",
       " 14: b'\\x0e',\n",
       " 15: b'\\x0f',\n",
       " 16: b'\\x10',\n",
       " 17: b'\\x11',\n",
       " 18: b'\\x12',\n",
       " 19: b'\\x13',\n",
       " 20: b'\\x14',\n",
       " 21: b'\\x15',\n",
       " 22: b'\\x16',\n",
       " 23: b'\\x17',\n",
       " 24: b'\\x18',\n",
       " 25: b'\\x19',\n",
       " 26: b'\\x1a',\n",
       " 27: b'\\x1b',\n",
       " 28: b'\\x1c',\n",
       " 29: b'\\x1d',\n",
       " 30: b'\\x1e',\n",
       " 31: b'\\x1f',\n",
       " 32: b' ',\n",
       " 33: b'!',\n",
       " 34: b'\"',\n",
       " 35: b'#',\n",
       " 36: b'$',\n",
       " 37: b'%',\n",
       " 38: b'&',\n",
       " 39: b\"'\",\n",
       " 40: b'(',\n",
       " 41: b')',\n",
       " 42: b'*',\n",
       " 43: b'+',\n",
       " 44: b',',\n",
       " 45: b'-',\n",
       " 46: b'.',\n",
       " 47: b'/',\n",
       " 48: b'0',\n",
       " 49: b'1',\n",
       " 50: b'2',\n",
       " 51: b'3',\n",
       " 52: b'4',\n",
       " 53: b'5',\n",
       " 54: b'6',\n",
       " 55: b'7',\n",
       " 56: b'8',\n",
       " 57: b'9',\n",
       " 58: b':',\n",
       " 59: b';',\n",
       " 60: b'<',\n",
       " 61: b'=',\n",
       " 62: b'>',\n",
       " 63: b'?',\n",
       " 64: b'@',\n",
       " 65: b'A',\n",
       " 66: b'B',\n",
       " 67: b'C',\n",
       " 68: b'D',\n",
       " 69: b'E',\n",
       " 70: b'F',\n",
       " 71: b'G',\n",
       " 72: b'H',\n",
       " 73: b'I',\n",
       " 74: b'J',\n",
       " 75: b'K',\n",
       " 76: b'L',\n",
       " 77: b'M',\n",
       " 78: b'N',\n",
       " 79: b'O',\n",
       " 80: b'P',\n",
       " 81: b'Q',\n",
       " 82: b'R',\n",
       " 83: b'S',\n",
       " 84: b'T',\n",
       " 85: b'U',\n",
       " 86: b'V',\n",
       " 87: b'W',\n",
       " 88: b'X',\n",
       " 89: b'Y',\n",
       " 90: b'Z',\n",
       " 91: b'[',\n",
       " 92: b'\\\\',\n",
       " 93: b']',\n",
       " 94: b'^',\n",
       " 95: b'_',\n",
       " 96: b'`',\n",
       " 97: b'a',\n",
       " 98: b'b',\n",
       " 99: b'c',\n",
       " 100: b'd',\n",
       " 101: b'e',\n",
       " 102: b'f',\n",
       " 103: b'g',\n",
       " 104: b'h',\n",
       " 105: b'i',\n",
       " 106: b'j',\n",
       " 107: b'k',\n",
       " 108: b'l',\n",
       " 109: b'm',\n",
       " 110: b'n',\n",
       " 111: b'o',\n",
       " 112: b'p',\n",
       " 113: b'q',\n",
       " 114: b'r',\n",
       " 115: b's',\n",
       " 116: b't',\n",
       " 117: b'u',\n",
       " 118: b'v',\n",
       " 119: b'w',\n",
       " 120: b'x',\n",
       " 121: b'y',\n",
       " 122: b'z',\n",
       " 123: b'{',\n",
       " 124: b'|',\n",
       " 125: b'}',\n",
       " 126: b'~',\n",
       " 127: b'\\x7f',\n",
       " 128: b'\\x80',\n",
       " 129: b'\\x81',\n",
       " 130: b'\\x82',\n",
       " 131: b'\\x83',\n",
       " 132: b'\\x84',\n",
       " 133: b'\\x85',\n",
       " 134: b'\\x86',\n",
       " 135: b'\\x87',\n",
       " 136: b'\\x88',\n",
       " 137: b'\\x89',\n",
       " 138: b'\\x8a',\n",
       " 139: b'\\x8b',\n",
       " 140: b'\\x8c',\n",
       " 141: b'\\x8d',\n",
       " 142: b'\\x8e',\n",
       " 143: b'\\x8f',\n",
       " 144: b'\\x90',\n",
       " 145: b'\\x91',\n",
       " 146: b'\\x92',\n",
       " 147: b'\\x93',\n",
       " 148: b'\\x94',\n",
       " 149: b'\\x95',\n",
       " 150: b'\\x96',\n",
       " 151: b'\\x97',\n",
       " 152: b'\\x98',\n",
       " 153: b'\\x99',\n",
       " 154: b'\\x9a',\n",
       " 155: b'\\x9b',\n",
       " 156: b'\\x9c',\n",
       " 157: b'\\x9d',\n",
       " 158: b'\\x9e',\n",
       " 159: b'\\x9f',\n",
       " 160: b'\\xa0',\n",
       " 161: b'\\xa1',\n",
       " 162: b'\\xa2',\n",
       " 163: b'\\xa3',\n",
       " 164: b'\\xa4',\n",
       " 165: b'\\xa5',\n",
       " 166: b'\\xa6',\n",
       " 167: b'\\xa7',\n",
       " 168: b'\\xa8',\n",
       " 169: b'\\xa9',\n",
       " 170: b'\\xaa',\n",
       " 171: b'\\xab',\n",
       " 172: b'\\xac',\n",
       " 173: b'\\xad',\n",
       " 174: b'\\xae',\n",
       " 175: b'\\xaf',\n",
       " 176: b'\\xb0',\n",
       " 177: b'\\xb1',\n",
       " 178: b'\\xb2',\n",
       " 179: b'\\xb3',\n",
       " 180: b'\\xb4',\n",
       " 181: b'\\xb5',\n",
       " 182: b'\\xb6',\n",
       " 183: b'\\xb7',\n",
       " 184: b'\\xb8',\n",
       " 185: b'\\xb9',\n",
       " 186: b'\\xba',\n",
       " 187: b'\\xbb',\n",
       " 188: b'\\xbc',\n",
       " 189: b'\\xbd',\n",
       " 190: b'\\xbe',\n",
       " 191: b'\\xbf',\n",
       " 192: b'\\xc0',\n",
       " 193: b'\\xc1',\n",
       " 194: b'\\xc2',\n",
       " 195: b'\\xc3',\n",
       " 196: b'\\xc4',\n",
       " 197: b'\\xc5',\n",
       " 198: b'\\xc6',\n",
       " 199: b'\\xc7',\n",
       " 200: b'\\xc8',\n",
       " 201: b'\\xc9',\n",
       " 202: b'\\xca',\n",
       " 203: b'\\xcb',\n",
       " 204: b'\\xcc',\n",
       " 205: b'\\xcd',\n",
       " 206: b'\\xce',\n",
       " 207: b'\\xcf',\n",
       " 208: b'\\xd0',\n",
       " 209: b'\\xd1',\n",
       " 210: b'\\xd2',\n",
       " 211: b'\\xd3',\n",
       " 212: b'\\xd4',\n",
       " 213: b'\\xd5',\n",
       " 214: b'\\xd6',\n",
       " 215: b'\\xd7',\n",
       " 216: b'\\xd8',\n",
       " 217: b'\\xd9',\n",
       " 218: b'\\xda',\n",
       " 219: b'\\xdb',\n",
       " 220: b'\\xdc',\n",
       " 221: b'\\xdd',\n",
       " 222: b'\\xde',\n",
       " 223: b'\\xdf',\n",
       " 224: b'\\xe0',\n",
       " 225: b'\\xe1',\n",
       " 226: b'\\xe2',\n",
       " 227: b'\\xe3',\n",
       " 228: b'\\xe4',\n",
       " 229: b'\\xe5',\n",
       " 230: b'\\xe6',\n",
       " 231: b'\\xe7',\n",
       " 232: b'\\xe8',\n",
       " 233: b'\\xe9',\n",
       " 234: b'\\xea',\n",
       " 235: b'\\xeb',\n",
       " 236: b'\\xec',\n",
       " 237: b'\\xed',\n",
       " 238: b'\\xee',\n",
       " 239: b'\\xef',\n",
       " 240: b'\\xf0',\n",
       " 241: b'\\xf1',\n",
       " 242: b'\\xf2',\n",
       " 243: b'\\xf3',\n",
       " 244: b'\\xf4',\n",
       " 245: b'\\xf5',\n",
       " 246: b'\\xf6',\n",
       " 247: b'\\xf7',\n",
       " 248: b'\\xf8',\n",
       " 249: b'\\xf9',\n",
       " 250: b'\\xfa',\n",
       " 251: b'\\xfb',\n",
       " 252: b'\\xfc',\n",
       " 253: b'\\xfd',\n",
       " 254: b'\\xfe',\n",
       " 255: b'\\xff',\n",
       " 256: b'e ',\n",
       " 257: b'\\xf0\\x9f',\n",
       " 258: b'\\xe2\\x80',\n",
       " 259: b'in',\n",
       " 260: b's ',\n",
       " 261: b'an',\n",
       " 262: b'th',\n",
       " 263: b'\\xf0\\x9f\\x85',\n",
       " 264: b'\\xf0\\x9f\\x87',\n",
       " 265: b'ar',\n",
       " 266: b'\\xef\\xbd',\n",
       " 267: b'\\xe2\\x80\\x8c',\n",
       " 268: b'\\xe2\\x80\\x8c\\xf0\\x9f\\x87',\n",
       " 269: b'er',\n",
       " 270: b'or',\n",
       " 271: b't ',\n",
       " 272: b'ing',\n",
       " 273: b'st',\n",
       " 274: b'and',\n",
       " 275: b' th',\n",
       " 276: b', ',\n",
       " 277: b'am',\n",
       " 278: b' the ',\n",
       " 279: b'ou',\n",
       " 280: b'Un',\n",
       " 281: b'Uni',\n",
       " 282: b'Unic',\n",
       " 283: b'Unico',\n",
       " 284: b'Unicod',\n",
       " 285: b's, ',\n",
       " 286: b'str',\n",
       " 287: b'ear',\n",
       " 288: b'and ',\n",
       " 289: b'int',\n",
       " 290: b'of',\n",
       " 291: b'. ',\n",
       " 292: b'll',\n",
       " 293: b'ing ',\n",
       " 294: b'an ',\n",
       " 295: b'en',\n",
       " 296: b'! ',\n",
       " 297: b'ver',\n",
       " 298: b'y ',\n",
       " 299: b'ame '}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6d24607-8989-40ea-896b-7f433a7710d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'hi hello \\xf0\\x9f\\x98\\x86, how are you doing ? \\xe3\\x81\\x8a\\xe5\\x85\\x83\\xe6\\xb0\\x97\\xe3\\x81\\xa7\\xe3\\x81\\x99\\xe3\\x81\\x8b '\n",
      "hi hello 😆, how are you doing ? お元気ですか \n"
     ]
    }
   ],
   "source": [
    "print(decode(encoded_random_str, vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7e83d3d0-80c3-47da-b48b-fed2b19084bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'お元気ですか'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b'\\xe3\\x81\\x8a\\xe5\\x85\\x83\\xe6\\xb0\\x97\\xe3\\x81\\xa7\\xe3\\x81\\x99\\xe3\\x81\\x8b'.decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed428cf1-6ae7-42ae-ad74-72fd7e208d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2pat = regex.compile(\n",
    "    r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25fd466e-ef60-4960-beae-26a680aa90e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hellow', ' how', \"'ve\", ' are', ' you', '?', '123', ' お元', ' 気', ' ですか']\n"
     ]
    }
   ],
   "source": [
    "print(regex.findall(gpt2pat, \"Hellow how've are you?123 お元 気 ですか\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d36b6c46-4fbc-4ef9-9039-aecf10ee94cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b2020e5-bb0b-4dd7-b47e-3bd10321a3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71, 5412, 1268, 527, 577, 9602]\n"
     ]
    }
   ],
   "source": [
    "print(enc.encode(\"hellow how are u ??\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b18241e-a688-4e4d-b005-9fcee63de2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a toy.txt file with some random text\n",
    "with open(\"test.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "  f.write(\"SentencePiece is an unsupervised text tokenizer and detokenizer mainly for Neural Network-based text generation systems where the vocabulary size is predetermined prior to the neural model training. SentencePiece implements subword units (e.g., byte-pair-encoding (BPE) [Sennrich et al.]) and unigram language model [Kudo.]) with the extension of direct training from raw sentences. SentencePiece allows us to make a purely end-to-end system that does not depend on language-specific pre/postprocessing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fac9e31-3a03-40a6-b738-f62a495d3fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(78) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: test.txt\n",
      "  input_format: text\n",
      "  model_prefix: tok400\n",
      "  model_type: BPE\n",
      "  vocab_size: 400\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.99995\n",
      "  input_sentence_size: 200000000\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 8\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 1\n",
      "  pretokenization_delimiter: \n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 1\n",
      "  required_chars: \n",
      "  byte_fallback: 1\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  seed_sentencepieces_file: \n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "  enable_differential_privacy: 0\n",
      "  differential_privacy_noise_level: 0\n",
      "  differential_privacy_clipping_threshold: 0\n",
      "}\n",
      "normalizer_spec {\n",
      "  name: identity\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 0\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(353) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(185) LOG(INFO) Loading corpus: test.txt\n",
      "trainer_interface.cc(409) LOG(INFO) Loaded all 1 sentences\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x00>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x01>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x02>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x03>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x04>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x05>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x06>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x07>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x08>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x09>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x0A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x0B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x0C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x0D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x0E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x0F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x10>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x11>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x12>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x13>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x14>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x15>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x16>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x17>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x18>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x19>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x1A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x1B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x1C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x1D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x1E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x1F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x20>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x21>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x22>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x23>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x24>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x25>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x26>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x27>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x28>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x29>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x2A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x2B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x2C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x2D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x2E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x2F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x30>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x31>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x32>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x33>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x34>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x35>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x36>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x37>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x38>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x39>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x3A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x3B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x3C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x3D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x3E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x3F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x40>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x41>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x42>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x43>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x44>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x45>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x46>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x47>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x48>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x49>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x4A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x4B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x4C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x4D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x4E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x4F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x50>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x51>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x52>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x53>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x54>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x55>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x56>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x57>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x58>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x59>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x5A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x5B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x5C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x5D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x5E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x5F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x60>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x61>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x62>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x63>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x64>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x65>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x66>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x67>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x68>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x69>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x6A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x6B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x6C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x6D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x6E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x6F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x70>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x71>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x72>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x73>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x74>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x75>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x76>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x77>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x78>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x79>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x7A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x7B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x7C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x7D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x7E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x7F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x80>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x81>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x82>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x83>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x84>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x85>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x86>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x87>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x88>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x89>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x8A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x8B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x8C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x8D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x8E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x8F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x90>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x91>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x92>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x93>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x94>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x95>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x96>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x97>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x98>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x99>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x9A>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x9B>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x9C>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x9D>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x9E>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0x9F>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA0>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA1>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA2>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA3>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA4>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA5>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA6>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA7>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA8>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xA9>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xAA>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xAB>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xAC>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xAD>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xAE>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xAF>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB0>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB1>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB2>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB3>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB4>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB5>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB6>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB7>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB8>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xB9>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xBA>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xBB>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xBC>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xBD>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xBE>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xBF>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC0>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC1>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC2>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC3>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC4>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC5>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC6>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC7>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC8>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xC9>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xCA>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xCB>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xCC>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xCD>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xCE>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xCF>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD0>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD1>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD2>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD3>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD4>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD5>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD6>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD7>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD8>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xD9>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xDA>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xDB>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xDC>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xDD>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xDE>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xDF>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE0>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE1>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE2>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE3>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE4>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE5>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE6>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0"
     ]
    }
   ],
   "source": [
    "# train a sentencepiece model on it\n",
    "# the settings here are (best effort) those used for training Llama 2\n",
    "import os\n",
    "\n",
    "options = dict(\n",
    "  # input spec\n",
    "  input=\"test.txt\",\n",
    "  input_format=\"text\",\n",
    "  # output spec\n",
    "  model_prefix=\"tok400\", # output filename prefix\n",
    "  # algorithm spec\n",
    "  # BPE alg\n",
    "  model_type=\"bpe\",\n",
    "  vocab_size=400,\n",
    "  # normalization\n",
    "  normalization_rule_name=\"identity\", # ew, turn off normalization\n",
    "  remove_extra_whitespaces=False,\n",
    "  input_sentence_size=200000000, # max number of training sentences\n",
    "  max_sentence_length=4192, # max number of bytes per sentence\n",
    "  seed_sentencepiece_size=1000000,\n",
    "  shuffle_input_sentence=True,\n",
    "  # rare word treatment\n",
    "  character_coverage=0.99995,\n",
    "  byte_fallback=True,\n",
    "  # merge rules\n",
    "  split_digits=True,\n",
    "  split_by_unicode_script=True,\n",
    "  split_by_whitespace=True,\n",
    "  split_by_number=True,\n",
    "  max_sentencepiece_length=16,\n",
    "  add_dummy_prefix=True,\n",
    "  allow_whitespace_only_pieces=True,\n",
    "  # special tokens\n",
    "  unk_id=0, # the UNK token MUST exist\n",
    "  bos_id=1, # the others are optional, set to -1 to turn off\n",
    "  eos_id=2,\n",
    "  pad_id=-1,\n",
    "  # systems\n",
    "  num_threads=os.cpu_count(), # use ~all system resources\n",
    ")\n",
    "\n",
    "sp.SentencePieceTrainer.train(**options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d178095-c064-44d7-a302-e46cba424506",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "xE7>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE8>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xE9>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xEA>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xEB>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xEC>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xED>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xEE>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xEF>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF0>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF1>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF2>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF3>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF4>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF5>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF6>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF7>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF8>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xF9>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xFA>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xFB>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xFC>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xFD>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xFE>\n",
      "trainer_interface.cc(425) LOG(INFO) Adding meta_piece: <0xFF>\n",
      "trainer_interface.cc(430) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(539) LOG(INFO) all chars count=504\n",
      "trainer_interface.cc(560) LOG(INFO) Alphabet size=39\n",
      "trainer_interface.cc(561) LOG(INFO) Final character coverage=1\n",
      "trainer_interface.cc(592) LOG(INFO) Done! preprocessed 1 sentences.\n",
      "trainer_interface.cc(598) LOG(INFO) Tokenizing input sentences with whitespace: 1\n",
      "trainer_interface.cc(609) LOG(INFO) Done! 58\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=18 min_freq=1\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=3 size=20 all=283 active=244 piece=ed\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=40 all=305 active=266 piece=.]\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=60 all=324 active=285 piece=ken\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=2 size=80 all=334 active=295 piece=▁model\n",
      "bpe_model_trainer.cc(268) LOG(INFO) Added: freq=1 size=100 all=338 active=299 piece=lo\n",
      "bpe_model_trainer.cc(159) LOG(INFO) Updating active symbols. max_freq=1 min_freq=0\n",
      "trainer_interface.cc(687) LOG(INFO) Saving model: tok400.model\n",
      "trainer_interface.cc(699) LOG(INFO) Saving vocabs: tok400.vocab\n"
     ]
    }
   ],
   "source": [
    "spm = sp.SentencePieceProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42804315-5bf0-45ae-976b-61cc5160604e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm.load('tok400.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19293504-4b64-48b8-8424-8e6972c7c36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [[spm.id_to_piece(idx), idx] for idx in range(spm.get_piece_size())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "05467bbc-3604-470f-98f3-96aa105796b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['<unk>', 0],\n",
       " ['<s>', 1],\n",
       " ['</s>', 2],\n",
       " ['<0x00>', 3],\n",
       " ['<0x01>', 4],\n",
       " ['<0x02>', 5],\n",
       " ['<0x03>', 6],\n",
       " ['<0x04>', 7],\n",
       " ['<0x05>', 8],\n",
       " ['<0x06>', 9],\n",
       " ['<0x07>', 10],\n",
       " ['<0x08>', 11],\n",
       " ['<0x09>', 12],\n",
       " ['<0x0A>', 13],\n",
       " ['<0x0B>', 14],\n",
       " ['<0x0C>', 15],\n",
       " ['<0x0D>', 16],\n",
       " ['<0x0E>', 17],\n",
       " ['<0x0F>', 18],\n",
       " ['<0x10>', 19],\n",
       " ['<0x11>', 20],\n",
       " ['<0x12>', 21],\n",
       " ['<0x13>', 22],\n",
       " ['<0x14>', 23],\n",
       " ['<0x15>', 24],\n",
       " ['<0x16>', 25],\n",
       " ['<0x17>', 26],\n",
       " ['<0x18>', 27],\n",
       " ['<0x19>', 28],\n",
       " ['<0x1A>', 29],\n",
       " ['<0x1B>', 30],\n",
       " ['<0x1C>', 31],\n",
       " ['<0x1D>', 32],\n",
       " ['<0x1E>', 33],\n",
       " ['<0x1F>', 34],\n",
       " ['<0x20>', 35],\n",
       " ['<0x21>', 36],\n",
       " ['<0x22>', 37],\n",
       " ['<0x23>', 38],\n",
       " ['<0x24>', 39],\n",
       " ['<0x25>', 40],\n",
       " ['<0x26>', 41],\n",
       " ['<0x27>', 42],\n",
       " ['<0x28>', 43],\n",
       " ['<0x29>', 44],\n",
       " ['<0x2A>', 45],\n",
       " ['<0x2B>', 46],\n",
       " ['<0x2C>', 47],\n",
       " ['<0x2D>', 48],\n",
       " ['<0x2E>', 49],\n",
       " ['<0x2F>', 50],\n",
       " ['<0x30>', 51],\n",
       " ['<0x31>', 52],\n",
       " ['<0x32>', 53],\n",
       " ['<0x33>', 54],\n",
       " ['<0x34>', 55],\n",
       " ['<0x35>', 56],\n",
       " ['<0x36>', 57],\n",
       " ['<0x37>', 58],\n",
       " ['<0x38>', 59],\n",
       " ['<0x39>', 60],\n",
       " ['<0x3A>', 61],\n",
       " ['<0x3B>', 62],\n",
       " ['<0x3C>', 63],\n",
       " ['<0x3D>', 64],\n",
       " ['<0x3E>', 65],\n",
       " ['<0x3F>', 66],\n",
       " ['<0x40>', 67],\n",
       " ['<0x41>', 68],\n",
       " ['<0x42>', 69],\n",
       " ['<0x43>', 70],\n",
       " ['<0x44>', 71],\n",
       " ['<0x45>', 72],\n",
       " ['<0x46>', 73],\n",
       " ['<0x47>', 74],\n",
       " ['<0x48>', 75],\n",
       " ['<0x49>', 76],\n",
       " ['<0x4A>', 77],\n",
       " ['<0x4B>', 78],\n",
       " ['<0x4C>', 79],\n",
       " ['<0x4D>', 80],\n",
       " ['<0x4E>', 81],\n",
       " ['<0x4F>', 82],\n",
       " ['<0x50>', 83],\n",
       " ['<0x51>', 84],\n",
       " ['<0x52>', 85],\n",
       " ['<0x53>', 86],\n",
       " ['<0x54>', 87],\n",
       " ['<0x55>', 88],\n",
       " ['<0x56>', 89],\n",
       " ['<0x57>', 90],\n",
       " ['<0x58>', 91],\n",
       " ['<0x59>', 92],\n",
       " ['<0x5A>', 93],\n",
       " ['<0x5B>', 94],\n",
       " ['<0x5C>', 95],\n",
       " ['<0x5D>', 96],\n",
       " ['<0x5E>', 97],\n",
       " ['<0x5F>', 98],\n",
       " ['<0x60>', 99],\n",
       " ['<0x61>', 100],\n",
       " ['<0x62>', 101],\n",
       " ['<0x63>', 102],\n",
       " ['<0x64>', 103],\n",
       " ['<0x65>', 104],\n",
       " ['<0x66>', 105],\n",
       " ['<0x67>', 106],\n",
       " ['<0x68>', 107],\n",
       " ['<0x69>', 108],\n",
       " ['<0x6A>', 109],\n",
       " ['<0x6B>', 110],\n",
       " ['<0x6C>', 111],\n",
       " ['<0x6D>', 112],\n",
       " ['<0x6E>', 113],\n",
       " ['<0x6F>', 114],\n",
       " ['<0x70>', 115],\n",
       " ['<0x71>', 116],\n",
       " ['<0x72>', 117],\n",
       " ['<0x73>', 118],\n",
       " ['<0x74>', 119],\n",
       " ['<0x75>', 120],\n",
       " ['<0x76>', 121],\n",
       " ['<0x77>', 122],\n",
       " ['<0x78>', 123],\n",
       " ['<0x79>', 124],\n",
       " ['<0x7A>', 125],\n",
       " ['<0x7B>', 126],\n",
       " ['<0x7C>', 127],\n",
       " ['<0x7D>', 128],\n",
       " ['<0x7E>', 129],\n",
       " ['<0x7F>', 130],\n",
       " ['<0x80>', 131],\n",
       " ['<0x81>', 132],\n",
       " ['<0x82>', 133],\n",
       " ['<0x83>', 134],\n",
       " ['<0x84>', 135],\n",
       " ['<0x85>', 136],\n",
       " ['<0x86>', 137],\n",
       " ['<0x87>', 138],\n",
       " ['<0x88>', 139],\n",
       " ['<0x89>', 140],\n",
       " ['<0x8A>', 141],\n",
       " ['<0x8B>', 142],\n",
       " ['<0x8C>', 143],\n",
       " ['<0x8D>', 144],\n",
       " ['<0x8E>', 145],\n",
       " ['<0x8F>', 146],\n",
       " ['<0x90>', 147],\n",
       " ['<0x91>', 148],\n",
       " ['<0x92>', 149],\n",
       " ['<0x93>', 150],\n",
       " ['<0x94>', 151],\n",
       " ['<0x95>', 152],\n",
       " ['<0x96>', 153],\n",
       " ['<0x97>', 154],\n",
       " ['<0x98>', 155],\n",
       " ['<0x99>', 156],\n",
       " ['<0x9A>', 157],\n",
       " ['<0x9B>', 158],\n",
       " ['<0x9C>', 159],\n",
       " ['<0x9D>', 160],\n",
       " ['<0x9E>', 161],\n",
       " ['<0x9F>', 162],\n",
       " ['<0xA0>', 163],\n",
       " ['<0xA1>', 164],\n",
       " ['<0xA2>', 165],\n",
       " ['<0xA3>', 166],\n",
       " ['<0xA4>', 167],\n",
       " ['<0xA5>', 168],\n",
       " ['<0xA6>', 169],\n",
       " ['<0xA7>', 170],\n",
       " ['<0xA8>', 171],\n",
       " ['<0xA9>', 172],\n",
       " ['<0xAA>', 173],\n",
       " ['<0xAB>', 174],\n",
       " ['<0xAC>', 175],\n",
       " ['<0xAD>', 176],\n",
       " ['<0xAE>', 177],\n",
       " ['<0xAF>', 178],\n",
       " ['<0xB0>', 179],\n",
       " ['<0xB1>', 180],\n",
       " ['<0xB2>', 181],\n",
       " ['<0xB3>', 182],\n",
       " ['<0xB4>', 183],\n",
       " ['<0xB5>', 184],\n",
       " ['<0xB6>', 185],\n",
       " ['<0xB7>', 186],\n",
       " ['<0xB8>', 187],\n",
       " ['<0xB9>', 188],\n",
       " ['<0xBA>', 189],\n",
       " ['<0xBB>', 190],\n",
       " ['<0xBC>', 191],\n",
       " ['<0xBD>', 192],\n",
       " ['<0xBE>', 193],\n",
       " ['<0xBF>', 194],\n",
       " ['<0xC0>', 195],\n",
       " ['<0xC1>', 196],\n",
       " ['<0xC2>', 197],\n",
       " ['<0xC3>', 198],\n",
       " ['<0xC4>', 199],\n",
       " ['<0xC5>', 200],\n",
       " ['<0xC6>', 201],\n",
       " ['<0xC7>', 202],\n",
       " ['<0xC8>', 203],\n",
       " ['<0xC9>', 204],\n",
       " ['<0xCA>', 205],\n",
       " ['<0xCB>', 206],\n",
       " ['<0xCC>', 207],\n",
       " ['<0xCD>', 208],\n",
       " ['<0xCE>', 209],\n",
       " ['<0xCF>', 210],\n",
       " ['<0xD0>', 211],\n",
       " ['<0xD1>', 212],\n",
       " ['<0xD2>', 213],\n",
       " ['<0xD3>', 214],\n",
       " ['<0xD4>', 215],\n",
       " ['<0xD5>', 216],\n",
       " ['<0xD6>', 217],\n",
       " ['<0xD7>', 218],\n",
       " ['<0xD8>', 219],\n",
       " ['<0xD9>', 220],\n",
       " ['<0xDA>', 221],\n",
       " ['<0xDB>', 222],\n",
       " ['<0xDC>', 223],\n",
       " ['<0xDD>', 224],\n",
       " ['<0xDE>', 225],\n",
       " ['<0xDF>', 226],\n",
       " ['<0xE0>', 227],\n",
       " ['<0xE1>', 228],\n",
       " ['<0xE2>', 229],\n",
       " ['<0xE3>', 230],\n",
       " ['<0xE4>', 231],\n",
       " ['<0xE5>', 232],\n",
       " ['<0xE6>', 233],\n",
       " ['<0xE7>', 234],\n",
       " ['<0xE8>', 235],\n",
       " ['<0xE9>', 236],\n",
       " ['<0xEA>', 237],\n",
       " ['<0xEB>', 238],\n",
       " ['<0xEC>', 239],\n",
       " ['<0xED>', 240],\n",
       " ['<0xEE>', 241],\n",
       " ['<0xEF>', 242],\n",
       " ['<0xF0>', 243],\n",
       " ['<0xF1>', 244],\n",
       " ['<0xF2>', 245],\n",
       " ['<0xF3>', 246],\n",
       " ['<0xF4>', 247],\n",
       " ['<0xF5>', 248],\n",
       " ['<0xF6>', 249],\n",
       " ['<0xF7>', 250],\n",
       " ['<0xF8>', 251],\n",
       " ['<0xF9>', 252],\n",
       " ['<0xFA>', 253],\n",
       " ['<0xFB>', 254],\n",
       " ['<0xFC>', 255],\n",
       " ['<0xFD>', 256],\n",
       " ['<0xFE>', 257],\n",
       " ['<0xFF>', 258],\n",
       " ['en', 259],\n",
       " ['▁t', 260],\n",
       " ['ce', 261],\n",
       " ['in', 262],\n",
       " ['ra', 263],\n",
       " ['▁a', 264],\n",
       " ['de', 265],\n",
       " ['er', 266],\n",
       " ['▁s', 267],\n",
       " ['ent', 268],\n",
       " ['or', 269],\n",
       " ['pr', 270],\n",
       " ['▁m', 271],\n",
       " ['▁u', 272],\n",
       " ['ing', 273],\n",
       " ['▁th', 274],\n",
       " ['ence', 275],\n",
       " ['entence', 276],\n",
       " ['Pi', 277],\n",
       " ['ed', 278],\n",
       " ['em', 279],\n",
       " ['ex', 280],\n",
       " ['is', 281],\n",
       " ['iz', 282],\n",
       " ['la', 283],\n",
       " ['on', 284],\n",
       " ['st', 285],\n",
       " ['▁S', 286],\n",
       " ['Pie', 287],\n",
       " ['end', 288],\n",
       " ['ext', 289],\n",
       " ['▁an', 290],\n",
       " ['▁pr', 291],\n",
       " ['▁to', 292],\n",
       " ['▁un', 293],\n",
       " ['▁the', 294],\n",
       " ['Piece', 295],\n",
       " ['▁Sentence', 296],\n",
       " ['▁SentencePiece', 297],\n",
       " ['.]', 298],\n",
       " ['Ne', 299],\n",
       " ['ag', 300],\n",
       " ['do', 301],\n",
       " ['ec', 302],\n",
       " ['gu', 303],\n",
       " ['ic', 304],\n",
       " ['ir', 305],\n",
       " ['it', 306],\n",
       " ['ly', 307],\n",
       " ['to', 308],\n",
       " ['▁(', 309],\n",
       " ['▁[', 310],\n",
       " ['▁f', 311],\n",
       " ['▁n', 312],\n",
       " ['▁w', 313],\n",
       " ['.])', 314],\n",
       " ['age', 315],\n",
       " ['del', 316],\n",
       " ['ion', 317],\n",
       " ['ken', 318],\n",
       " ['lan', 319],\n",
       " ['ral', 320],\n",
       " ['wor', 321],\n",
       " ['yst', 322],\n",
       " ['▁Ne', 323],\n",
       " ['▁al', 324],\n",
       " ['▁de', 325],\n",
       " ['▁is', 326],\n",
       " ['▁ma', 327],\n",
       " ['▁mo', 328],\n",
       " ['izer', 329],\n",
       " ['rain', 330],\n",
       " ['ural', 331],\n",
       " ['▁and', 332],\n",
       " ['▁lan', 333],\n",
       " ['▁pre', 334],\n",
       " ['guage', 335],\n",
       " ['ystem', 336],\n",
       " ['▁text', 337],\n",
       " ['▁model', 338],\n",
       " ['▁train', 339],\n",
       " ['kenizer', 340],\n",
       " ['▁system', 341],\n",
       " ['▁language', 342],\n",
       " ['▁training', 343],\n",
       " ['.,', 344],\n",
       " ['BP', 345],\n",
       " ['Ku', 346],\n",
       " ['ab', 347],\n",
       " ['as', 348],\n",
       " ['at', 349],\n",
       " ['by', 350],\n",
       " ['co', 351],\n",
       " ['es', 352],\n",
       " ['et', 353],\n",
       " ['if', 354],\n",
       " ['ig', 355],\n",
       " ['im', 356],\n",
       " ['ke', 357],\n",
       " ['lo', 358],\n",
       " ['nr', 359],\n",
       " ['oc', 360],\n",
       " ['e', 361],\n",
       " ['▁', 362],\n",
       " ['n', 363],\n",
       " ['t', 364],\n",
       " ['i', 365],\n",
       " ['r', 366],\n",
       " ['a', 367],\n",
       " ['o', 368],\n",
       " ['s', 369],\n",
       " ['d', 370],\n",
       " ['c', 371],\n",
       " ['l', 372],\n",
       " ['u', 373],\n",
       " ['g', 374],\n",
       " ['m', 375],\n",
       " ['p', 376],\n",
       " ['.', 377],\n",
       " ['h', 378],\n",
       " ['-', 379],\n",
       " ['w', 380],\n",
       " ['y', 381],\n",
       " ['P', 382],\n",
       " ['S', 383],\n",
       " ['b', 384],\n",
       " ['f', 385],\n",
       " ['k', 386],\n",
       " [')', 387],\n",
       " ['x', 388],\n",
       " ['z', 389],\n",
       " ['(', 390],\n",
       " ['N', 391],\n",
       " ['[', 392],\n",
       " [']', 393],\n",
       " ['v', 394],\n",
       " [',', 395],\n",
       " ['/', 396],\n",
       " ['B', 397],\n",
       " ['E', 398],\n",
       " ['K', 399]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a28e0a89-f8ac-42cb-b10b-0856dcf6d38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_ids = spm.encode(\"hello こんにちは\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "65eb2b9e-3701-4fdc-aa45-8a11d17ca7c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[362,\n",
       " 378,\n",
       " 361,\n",
       " 372,\n",
       " 358,\n",
       " 362,\n",
       " 230,\n",
       " 132,\n",
       " 150,\n",
       " 230,\n",
       " 133,\n",
       " 150,\n",
       " 230,\n",
       " 132,\n",
       " 174,\n",
       " 230,\n",
       " 132,\n",
       " 164,\n",
       " 230,\n",
       " 132,\n",
       " 178]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af25e459-8911-4e01-9800-219154ff6b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁', 'h', 'e', 'l', 'lo', '▁', '<0xE3>', '<0x81>', '<0x93>', '<0xE3>', '<0x82>', '<0x93>', '<0xE3>', '<0x81>', '<0xAB>', '<0xE3>', '<0x81>', '<0xA1>', '<0xE3>', '<0x81>', '<0xAF>']\n"
     ]
    }
   ],
   "source": [
    "print([spm.id_to_piece(idx) for idx in sp_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9695598-2915-49c1-bff5-64aab4a44421",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
